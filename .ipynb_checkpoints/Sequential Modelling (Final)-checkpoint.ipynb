{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ceb1ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>is_male</th>\n",
       "      <th>CP_TA</th>\n",
       "      <th>CP_ATA</th>\n",
       "      <th>CP_ASY</th>\n",
       "      <th>CP_NAP</th>\n",
       "      <th>ECG_normal</th>\n",
       "      <th>ECG_ST</th>\n",
       "      <th>ECG_LVH</th>\n",
       "      <th>ST_Up</th>\n",
       "      <th>ST_Down</th>\n",
       "      <th>ST_Flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>45</td>\n",
       "      <td>115</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>52</td>\n",
       "      <td>112</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>51</td>\n",
       "      <td>137</td>\n",
       "      <td>339</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  Oldpeak  \\\n",
       "847   45        115          260          0    185               0      0.0   \n",
       "363   56        120            0          0    148               0      0.0   \n",
       "59    52        112          342          0     96               1      1.0   \n",
       "493   51        137          339          0    127               1      1.7   \n",
       "236   41        120          336          0    118               1      3.0   \n",
       "\n",
       "     HeartDisease  is_male  CP_TA  CP_ATA  CP_ASY  CP_NAP  ECG_normal  ECG_ST  \\\n",
       "847             0        1      0       0       1       0           0       0   \n",
       "363             1        1      0       0       1       0           0       1   \n",
       "59              1        1      0       0       1       0           0       1   \n",
       "493             1        1      0       0       0       1           1       0   \n",
       "236             1        1      0       0       1       0           1       0   \n",
       "\n",
       "     ECG_LVH  ST_Up  ST_Down  ST_Flat  \n",
       "847        1      1        0        0  \n",
       "363        0      0        0        1  \n",
       "59         0      0        0        1  \n",
       "493        0      0        0        1  \n",
       "236        0      0        0        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart_mod_ohe.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598cda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to split data into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "Y = df['HeartDisease']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, \n",
    "    test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af813b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "795   42    1              1        120          240          1           0   \n",
       "25    36    1              1        130          209          0           0   \n",
       "84    56    1              0        150          213          1           0   \n",
       "10    37    0              1        130          211          0           0   \n",
       "344   51    1              0        120            0          1           0   \n",
       "..   ...  ...            ...        ...          ...        ...         ...   \n",
       "106   48    0              0        120          254          0           2   \n",
       "270   45    1              0        120          225          0           0   \n",
       "860   60    1              0        130          253          0           0   \n",
       "435   60    1              0        152            0          0           2   \n",
       "102   40    0              0        150          392          0           0   \n",
       "\n",
       "     MaxHR  ExerciseAngina  Oldpeak  ST_Slope  \n",
       "795    194               0      0.8         2  \n",
       "25     178               0      0.0         1  \n",
       "84     125               1      1.0         0  \n",
       "10     142               0      0.0         1  \n",
       "344    104               0      0.0         0  \n",
       "..     ...             ...      ...       ...  \n",
       "106    110               0      0.0         1  \n",
       "270    140               0      0.0         1  \n",
       "860    144               1      1.4         1  \n",
       "435    118               1      0.0         1  \n",
       "102    130               0      2.0         0  \n",
       "\n",
       "[734 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8734363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795    0\n",
       "25     0\n",
       "84     1\n",
       "10     0\n",
       "344    1\n",
       "      ..\n",
       "106    0\n",
       "270    0\n",
       "860    1\n",
       "435    0\n",
       "102    1\n",
       "Name: HeartDisease, Length: 734, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212859c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "\n",
    "#Scaling the data \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ff6fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.6287 - accuracy: 0.6649 - precision: 0.6264 - recall: 0.9576\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.4651 - accuracy: 0.8338 - precision: 0.8121 - recall: 0.9052\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.4027 - accuracy: 0.8474 - precision: 0.8384 - recall: 0.8928\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3736 - accuracy: 0.8542 - precision: 0.8500 - recall: 0.8903\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3582 - accuracy: 0.8610 - precision: 0.8620 - recall: 0.8878\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.3487 - accuracy: 0.8610 - precision: 0.8602 - recall: 0.8903\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3426 - accuracy: 0.8678 - precision: 0.8671 - recall: 0.8953\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.3378 - accuracy: 0.8665 - precision: 0.8651 - recall: 0.8953\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.3342 - accuracy: 0.8719 - precision: 0.8681 - recall: 0.9027\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 523us/step - loss: 0.3310 - accuracy: 0.8747 - precision: 0.8687 - recall: 0.9077\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3284 - accuracy: 0.8760 - precision: 0.8708 - recall: 0.9077\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3258 - accuracy: 0.8774 - precision: 0.8747 - recall: 0.9052\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.3237 - accuracy: 0.8787 - precision: 0.8750 - recall: 0.9077\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3211 - accuracy: 0.8774 - precision: 0.8747 - recall: 0.9052\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3192 - accuracy: 0.8760 - precision: 0.8744 - recall: 0.9027\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.3170 - accuracy: 0.8801 - precision: 0.8771 - recall: 0.9077\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.3154 - accuracy: 0.8787 - precision: 0.8768 - recall: 0.9052\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.3136 - accuracy: 0.8815 - precision: 0.8792 - recall: 0.9077\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3115 - accuracy: 0.8842 - precision: 0.8798 - recall: 0.9127\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3101 - accuracy: 0.8828 - precision: 0.8795 - recall: 0.9102\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3084 - accuracy: 0.8842 - precision: 0.8816 - recall: 0.9102\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3069 - accuracy: 0.8815 - precision: 0.8774 - recall: 0.9102\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3055 - accuracy: 0.8869 - precision: 0.8822 - recall: 0.9152\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3037 - accuracy: 0.8883 - precision: 0.8862 - recall: 0.9127\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.3021 - accuracy: 0.8896 - precision: 0.8865 - recall: 0.9152\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.3007 - accuracy: 0.8896 - precision: 0.8846 - recall: 0.9177\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2992 - accuracy: 0.8910 - precision: 0.8849 - recall: 0.9202\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2979 - accuracy: 0.8910 - precision: 0.8867 - recall: 0.9177\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2964 - accuracy: 0.8937 - precision: 0.8873 - recall: 0.9227\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2949 - accuracy: 0.8924 - precision: 0.8870 - recall: 0.9202\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2937 - accuracy: 0.8896 - precision: 0.8828 - recall: 0.9202\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2923 - accuracy: 0.8924 - precision: 0.8852 - recall: 0.9227\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2911 - accuracy: 0.8896 - precision: 0.8828 - recall: 0.9202\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2901 - accuracy: 0.8924 - precision: 0.8870 - recall: 0.9202\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2885 - accuracy: 0.8951 - precision: 0.8894 - recall: 0.9227\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 479us/step - loss: 0.2871 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2861 - accuracy: 0.8937 - precision: 0.8854 - recall: 0.9252\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2848 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2840 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2829 - accuracy: 0.8965 - precision: 0.8878 - recall: 0.9277\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2817 - accuracy: 0.8965 - precision: 0.8878 - recall: 0.9277\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2806 - accuracy: 0.8965 - precision: 0.8897 - recall: 0.9252\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2796 - accuracy: 0.8965 - precision: 0.8916 - recall: 0.9227\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2788 - accuracy: 0.8965 - precision: 0.8878 - recall: 0.9277\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2775 - accuracy: 0.8965 - precision: 0.8878 - recall: 0.9277\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2764 - accuracy: 0.8992 - precision: 0.8940 - recall: 0.9252\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2753 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2746 - accuracy: 0.8978 - precision: 0.8881 - recall: 0.9302\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2736 - accuracy: 0.8978 - precision: 0.8900 - recall: 0.9277\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2725 - accuracy: 0.8965 - precision: 0.8897 - recall: 0.9252\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2714 - accuracy: 0.8978 - precision: 0.8918 - recall: 0.9252\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2709 - accuracy: 0.8978 - precision: 0.8881 - recall: 0.9302\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2698 - accuracy: 0.8992 - precision: 0.8921 - recall: 0.9277\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2692 - accuracy: 0.8978 - precision: 0.8900 - recall: 0.9277\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2683 - accuracy: 0.8978 - precision: 0.8918 - recall: 0.9252\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 479us/step - loss: 0.2673 - accuracy: 0.8978 - precision: 0.8900 - recall: 0.9277\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2666 - accuracy: 0.8965 - precision: 0.8860 - recall: 0.9302\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2655 - accuracy: 0.8992 - precision: 0.8940 - recall: 0.9252\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2648 - accuracy: 0.8978 - precision: 0.8918 - recall: 0.9252\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 522us/step - loss: 0.2641 - accuracy: 0.8965 - precision: 0.8916 - recall: 0.9227\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2629 - accuracy: 0.8992 - precision: 0.8921 - recall: 0.9277\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2623 - accuracy: 0.8978 - precision: 0.8900 - recall: 0.9277\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2614 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2609 - accuracy: 0.9005 - precision: 0.8961 - recall: 0.9252\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2595 - accuracy: 0.8978 - precision: 0.8918 - recall: 0.9252\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2589 - accuracy: 0.8978 - precision: 0.8918 - recall: 0.9252\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2584 - accuracy: 0.8992 - precision: 0.8940 - recall: 0.9252\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2574 - accuracy: 0.9019 - precision: 0.8983 - recall: 0.9252\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2564 - accuracy: 0.9005 - precision: 0.8961 - recall: 0.9252\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2555 - accuracy: 0.8992 - precision: 0.8921 - recall: 0.9277\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2551 - accuracy: 0.9019 - precision: 0.8983 - recall: 0.9252\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 479us/step - loss: 0.2542 - accuracy: 0.9005 - precision: 0.8961 - recall: 0.9252\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2529 - accuracy: 0.9033 - precision: 0.9005 - recall: 0.9252\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2527 - accuracy: 0.9005 - precision: 0.9000 - recall: 0.9202\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2519 - accuracy: 0.9019 - precision: 0.8983 - recall: 0.9252\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2509 - accuracy: 0.9033 - precision: 0.9005 - recall: 0.9252\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2501 - accuracy: 0.9019 - precision: 0.8983 - recall: 0.9252\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2497 - accuracy: 0.9033 - precision: 0.9024 - recall: 0.9227\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2489 - accuracy: 0.8992 - precision: 0.8921 - recall: 0.9277\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2481 - accuracy: 0.9033 - precision: 0.9005 - recall: 0.9252\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2477 - accuracy: 0.9033 - precision: 0.9024 - recall: 0.9227\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2468 - accuracy: 0.9046 - precision: 0.8988 - recall: 0.9302\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2463 - accuracy: 0.9033 - precision: 0.9024 - recall: 0.9227\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2456 - accuracy: 0.9060 - precision: 0.9049 - recall: 0.9252\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2450 - accuracy: 0.9060 - precision: 0.9049 - recall: 0.9252\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2444 - accuracy: 0.9060 - precision: 0.9029 - recall: 0.9277\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2431 - accuracy: 0.9060 - precision: 0.9029 - recall: 0.9277\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2428 - accuracy: 0.9074 - precision: 0.9051 - recall: 0.9277\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2424 - accuracy: 0.9074 - precision: 0.9031 - recall: 0.9302\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2415 - accuracy: 0.9060 - precision: 0.9029 - recall: 0.9277\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2411 - accuracy: 0.9046 - precision: 0.8988 - recall: 0.9302\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2403 - accuracy: 0.9074 - precision: 0.9051 - recall: 0.9277\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2399 - accuracy: 0.9074 - precision: 0.9071 - recall: 0.9252\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2389 - accuracy: 0.9074 - precision: 0.9031 - recall: 0.9302\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2384 - accuracy: 0.9046 - precision: 0.9027 - recall: 0.9252\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2374 - accuracy: 0.9074 - precision: 0.9012 - recall: 0.9327\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2372 - accuracy: 0.9087 - precision: 0.9073 - recall: 0.9277\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2369 - accuracy: 0.9060 - precision: 0.9010 - recall: 0.9302\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2359 - accuracy: 0.9060 - precision: 0.9049 - recall: 0.9252\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 522us/step - loss: 0.2350 - accuracy: 0.9074 - precision: 0.9012 - recall: 0.9327\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "#SGD optimization is Stochastic Gradient Descent (with momentum)\n",
    "\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'), #adds layer of 128 dense neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model1.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.05), #lr is learning rate,SGD is the optimizer\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history1 = model1.fit(X_train_scaled, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e043823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.6874 - accuracy: 0.5312 - precision: 0.5667 - recall: 0.8947WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.6140 - accuracy: 0.6757 - precision: 0.6338 - recall: 0.9626\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.4764 - accuracy: 0.8447 - precision: 0.8254 - recall: 0.9077\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.4003 - accuracy: 0.8556 - precision: 0.8487 - recall: 0.8953\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.3645 - accuracy: 0.8610 - precision: 0.8568 - recall: 0.8953\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.3472 - accuracy: 0.8651 - precision: 0.8647 - recall: 0.8928\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.3367 - accuracy: 0.8747 - precision: 0.8723 - recall: 0.9027\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 631us/step - loss: 0.3304 - accuracy: 0.8760 - precision: 0.8799 - recall: 0.8953\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.3246 - accuracy: 0.8760 - precision: 0.8762 - recall: 0.9002\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.3200 - accuracy: 0.8774 - precision: 0.8802 - recall: 0.8978\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.3158 - accuracy: 0.8815 - precision: 0.8756 - recall: 0.9127\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.3128 - accuracy: 0.8842 - precision: 0.8873 - recall: 0.9027\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.3087 - accuracy: 0.8815 - precision: 0.8848 - recall: 0.9002\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.3058 - accuracy: 0.8842 - precision: 0.8835 - recall: 0.9077\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.3021 - accuracy: 0.8856 - precision: 0.8838 - recall: 0.9102\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2994 - accuracy: 0.8869 - precision: 0.8859 - recall: 0.9102\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2958 - accuracy: 0.8883 - precision: 0.8843 - recall: 0.9152\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2937 - accuracy: 0.8883 - precision: 0.8862 - recall: 0.9127\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2911 - accuracy: 0.8910 - precision: 0.8867 - recall: 0.9177\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2879 - accuracy: 0.8924 - precision: 0.8870 - recall: 0.9202\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2859 - accuracy: 0.8937 - precision: 0.8892 - recall: 0.9202\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2832 - accuracy: 0.8937 - precision: 0.8892 - recall: 0.9202\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2809 - accuracy: 0.8937 - precision: 0.8854 - recall: 0.9252\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2791 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 594us/step - loss: 0.2761 - accuracy: 0.8937 - precision: 0.8892 - recall: 0.9202\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2739 - accuracy: 0.8951 - precision: 0.8894 - recall: 0.9227\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2718 - accuracy: 0.8937 - precision: 0.8873 - recall: 0.9227\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2695 - accuracy: 0.8965 - precision: 0.8878 - recall: 0.9277\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2677 - accuracy: 0.8992 - precision: 0.8959 - recall: 0.9227\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2652 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2629 - accuracy: 0.8992 - precision: 0.8940 - recall: 0.9252\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2612 - accuracy: 0.9019 - precision: 0.8983 - recall: 0.9252\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2586 - accuracy: 0.9019 - precision: 0.8945 - recall: 0.9302\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2567 - accuracy: 0.9005 - precision: 0.8961 - recall: 0.9252\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2559 - accuracy: 0.9019 - precision: 0.9002 - recall: 0.9227\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2532 - accuracy: 0.9033 - precision: 0.9005 - recall: 0.9252\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2505 - accuracy: 0.9074 - precision: 0.9051 - recall: 0.9277\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2487 - accuracy: 0.9060 - precision: 0.9049 - recall: 0.9252\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2469 - accuracy: 0.9074 - precision: 0.9071 - recall: 0.9252\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2458 - accuracy: 0.8992 - precision: 0.8940 - recall: 0.9252\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2439 - accuracy: 0.9060 - precision: 0.9010 - recall: 0.9302\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2417 - accuracy: 0.9046 - precision: 0.9007 - recall: 0.9277\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2399 - accuracy: 0.9074 - precision: 0.9051 - recall: 0.9277\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2375 - accuracy: 0.9101 - precision: 0.9115 - recall: 0.9252\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2370 - accuracy: 0.9074 - precision: 0.9012 - recall: 0.9327\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2349 - accuracy: 0.9101 - precision: 0.9115 - recall: 0.9252\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2327 - accuracy: 0.9142 - precision: 0.9142 - recall: 0.9302\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2305 - accuracy: 0.9114 - precision: 0.9058 - recall: 0.9352\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2303 - accuracy: 0.9169 - precision: 0.9167 - recall: 0.9327\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2288 - accuracy: 0.9101 - precision: 0.9095 - recall: 0.9277\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2259 - accuracy: 0.9114 - precision: 0.9078 - recall: 0.9327\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2243 - accuracy: 0.9114 - precision: 0.9118 - recall: 0.9277\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2233 - accuracy: 0.9128 - precision: 0.9140 - recall: 0.9277\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2222 - accuracy: 0.9142 - precision: 0.9142 - recall: 0.9302\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2211 - accuracy: 0.9142 - precision: 0.9142 - recall: 0.9302\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2188 - accuracy: 0.9128 - precision: 0.9100 - recall: 0.9327\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2176 - accuracy: 0.9114 - precision: 0.9118 - recall: 0.9277\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2160 - accuracy: 0.9223 - precision: 0.9175 - recall: 0.9426\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.2139 - accuracy: 0.9196 - precision: 0.9212 - recall: 0.9327\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2127 - accuracy: 0.9169 - precision: 0.9187 - recall: 0.9302\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.2121 - accuracy: 0.9142 - precision: 0.9183 - recall: 0.9252\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2098 - accuracy: 0.9169 - precision: 0.9208 - recall: 0.9277\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2079 - accuracy: 0.9210 - precision: 0.9173 - recall: 0.9401\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2077 - accuracy: 0.9169 - precision: 0.9208 - recall: 0.9277\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2062 - accuracy: 0.9169 - precision: 0.9187 - recall: 0.9302\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2031 - accuracy: 0.9223 - precision: 0.9236 - recall: 0.9352\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2024 - accuracy: 0.9210 - precision: 0.9214 - recall: 0.9352\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.2018 - accuracy: 0.9264 - precision: 0.9263 - recall: 0.9401\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1988 - accuracy: 0.9223 - precision: 0.9236 - recall: 0.9352\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1976 - accuracy: 0.9251 - precision: 0.9261 - recall: 0.9377\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1957 - accuracy: 0.9210 - precision: 0.9193 - recall: 0.9377\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1958 - accuracy: 0.9223 - precision: 0.9216 - recall: 0.9377\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1943 - accuracy: 0.9251 - precision: 0.9240 - recall: 0.9401\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 653us/step - loss: 0.1909 - accuracy: 0.9251 - precision: 0.9240 - recall: 0.9401\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1910 - accuracy: 0.9237 - precision: 0.9218 - recall: 0.9401\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1892 - accuracy: 0.9251 - precision: 0.9220 - recall: 0.9426\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1871 - accuracy: 0.9251 - precision: 0.9240 - recall: 0.9401\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1857 - accuracy: 0.9251 - precision: 0.9261 - recall: 0.9377\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 574us/step - loss: 0.1843 - accuracy: 0.9305 - precision: 0.9310 - recall: 0.9426\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1844 - accuracy: 0.9251 - precision: 0.9199 - recall: 0.9451\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1816 - accuracy: 0.9278 - precision: 0.9286 - recall: 0.9401\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1813 - accuracy: 0.9264 - precision: 0.9242 - recall: 0.9426\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1791 - accuracy: 0.9292 - precision: 0.9246 - recall: 0.9476\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1786 - accuracy: 0.9319 - precision: 0.9291 - recall: 0.9476\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 607us/step - loss: 0.1779 - accuracy: 0.9264 - precision: 0.9305 - recall: 0.9352\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1755 - accuracy: 0.9278 - precision: 0.9286 - recall: 0.9401\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1752 - accuracy: 0.9278 - precision: 0.9244 - recall: 0.9451\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1715 - accuracy: 0.9332 - precision: 0.9293 - recall: 0.9501\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1706 - accuracy: 0.9305 - precision: 0.9353 - recall: 0.9377\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1696 - accuracy: 0.9319 - precision: 0.9270 - recall: 0.9501\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 562us/step - loss: 0.1684 - accuracy: 0.9332 - precision: 0.9335 - recall: 0.9451\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1678 - accuracy: 0.9332 - precision: 0.9335 - recall: 0.9451\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1653 - accuracy: 0.9237 - precision: 0.9238 - recall: 0.9377\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1657 - accuracy: 0.9360 - precision: 0.9381 - recall: 0.9451\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1626 - accuracy: 0.9319 - precision: 0.9270 - recall: 0.9501\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 566us/step - loss: 0.1623 - accuracy: 0.9292 - precision: 0.9246 - recall: 0.9476\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 576us/step - loss: 0.1603 - accuracy: 0.9373 - precision: 0.9340 - recall: 0.9526\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1600 - accuracy: 0.9414 - precision: 0.9431 - recall: 0.9501\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1585 - accuracy: 0.9346 - precision: 0.9294 - recall: 0.9526\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1568 - accuracy: 0.9373 - precision: 0.9404 - recall: 0.9451\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 609us/step - loss: 0.1542 - accuracy: 0.9401 - precision: 0.9364 - recall: 0.9551\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "#ADDED A SECOND LAYER OF NEURONS\n",
    "\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'), #adds layer of 128 dense neurons\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # adds another layer with 128 neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.05), #lr is learning rate,SGD is the optimizer\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history2 = model2.fit(X_train_scaled, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d99e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.6566 - accuracy: 0.6444 - precision: 0.6423 - recall: 0.7880\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.5358 - accuracy: 0.8392 - precision: 0.8238 - recall: 0.8978\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.4208 - accuracy: 0.8501 - precision: 0.8456 - recall: 0.8878\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3612 - accuracy: 0.8665 - precision: 0.8668 - recall: 0.8928\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3400 - accuracy: 0.8706 - precision: 0.8714 - recall: 0.8953\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3290 - accuracy: 0.8747 - precision: 0.8705 - recall: 0.9052\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3231 - accuracy: 0.8774 - precision: 0.8747 - recall: 0.9052\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3180 - accuracy: 0.8760 - precision: 0.8708 - recall: 0.9077\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3124 - accuracy: 0.8787 - precision: 0.8805 - recall: 0.9002\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3075 - accuracy: 0.8828 - precision: 0.8759 - recall: 0.9152\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3044 - accuracy: 0.8883 - precision: 0.8900 - recall: 0.9077\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2990 - accuracy: 0.8856 - precision: 0.8819 - recall: 0.9127\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2955 - accuracy: 0.8856 - precision: 0.8838 - recall: 0.9102\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2906 - accuracy: 0.8896 - precision: 0.8865 - recall: 0.9152\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2876 - accuracy: 0.8924 - precision: 0.8889 - recall: 0.9177\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2824 - accuracy: 0.8896 - precision: 0.8846 - recall: 0.9177\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2795 - accuracy: 0.8937 - precision: 0.8910 - recall: 0.9177\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2765 - accuracy: 0.8924 - precision: 0.8889 - recall: 0.9177\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2717 - accuracy: 0.8951 - precision: 0.8913 - recall: 0.9202\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2695 - accuracy: 0.8978 - precision: 0.8937 - recall: 0.9227\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2653 - accuracy: 0.9005 - precision: 0.8981 - recall: 0.9227\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2621 - accuracy: 0.9019 - precision: 0.8964 - recall: 0.9277\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2606 - accuracy: 0.9033 - precision: 0.8986 - recall: 0.9277\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2555 - accuracy: 0.8978 - precision: 0.8937 - recall: 0.9227\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2527 - accuracy: 0.9019 - precision: 0.8964 - recall: 0.9277\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2501 - accuracy: 0.9033 - precision: 0.8966 - recall: 0.9302\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2461 - accuracy: 0.9046 - precision: 0.8988 - recall: 0.9302\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2453 - accuracy: 0.9019 - precision: 0.9002 - recall: 0.9227\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2406 - accuracy: 0.9046 - precision: 0.9007 - recall: 0.9277\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2376 - accuracy: 0.9046 - precision: 0.8988 - recall: 0.9302\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2354 - accuracy: 0.9101 - precision: 0.8998 - recall: 0.9401\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2307 - accuracy: 0.9074 - precision: 0.9071 - recall: 0.9252\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2283 - accuracy: 0.9128 - precision: 0.9041 - recall: 0.9401\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2280 - accuracy: 0.9114 - precision: 0.9118 - recall: 0.9277\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2245 - accuracy: 0.9128 - precision: 0.9080 - recall: 0.9352\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2187 - accuracy: 0.9169 - precision: 0.9187 - recall: 0.9302\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2161 - accuracy: 0.9155 - precision: 0.9124 - recall: 0.9352\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2141 - accuracy: 0.9169 - precision: 0.9187 - recall: 0.9302\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2135 - accuracy: 0.9196 - precision: 0.9212 - recall: 0.9327\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2102 - accuracy: 0.9196 - precision: 0.9171 - recall: 0.9377\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.2080 - accuracy: 0.9169 - precision: 0.9187 - recall: 0.9302\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2033 - accuracy: 0.9237 - precision: 0.9177 - recall: 0.9451\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1995 - accuracy: 0.9264 - precision: 0.9305 - recall: 0.9352\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.2005 - accuracy: 0.9183 - precision: 0.9189 - recall: 0.9327\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1971 - accuracy: 0.9210 - precision: 0.9256 - recall: 0.9302\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1916 - accuracy: 0.9292 - precision: 0.9287 - recall: 0.9426\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1885 - accuracy: 0.9292 - precision: 0.9287 - recall: 0.9426\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1885 - accuracy: 0.9251 - precision: 0.9261 - recall: 0.9377\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1878 - accuracy: 0.9251 - precision: 0.9261 - recall: 0.9377\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1807 - accuracy: 0.9305 - precision: 0.9268 - recall: 0.9476\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1809 - accuracy: 0.9278 - precision: 0.9265 - recall: 0.9426\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1760 - accuracy: 0.9319 - precision: 0.9291 - recall: 0.9476\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1759 - accuracy: 0.9332 - precision: 0.9356 - recall: 0.9426\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.1733 - accuracy: 0.9305 - precision: 0.9332 - recall: 0.9401\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1685 - accuracy: 0.9346 - precision: 0.9315 - recall: 0.9501\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1681 - accuracy: 0.9332 - precision: 0.9251 - recall: 0.9551\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1666 - accuracy: 0.9373 - precision: 0.9383 - recall: 0.9476\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1603 - accuracy: 0.9428 - precision: 0.9476 - recall: 0.9476\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1593 - accuracy: 0.9387 - precision: 0.9341 - recall: 0.9551\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 696us/step - loss: 0.1572 - accuracy: 0.9346 - precision: 0.9337 - recall: 0.9476\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1532 - accuracy: 0.9469 - precision: 0.9458 - recall: 0.9576\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1490 - accuracy: 0.9441 - precision: 0.9500 - recall: 0.9476\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1492 - accuracy: 0.9401 - precision: 0.9364 - recall: 0.9551\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1439 - accuracy: 0.9537 - precision: 0.9553 - recall: 0.9601\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1406 - accuracy: 0.9455 - precision: 0.9457 - recall: 0.9551\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1394 - accuracy: 0.9482 - precision: 0.9438 - recall: 0.9626\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1396 - accuracy: 0.9550 - precision: 0.9554 - recall: 0.9626\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.1303 - accuracy: 0.9591 - precision: 0.9603 - recall: 0.9651\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1278 - accuracy: 0.9496 - precision: 0.9505 - recall: 0.9576\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.1248 - accuracy: 0.9537 - precision: 0.9576 - recall: 0.9576\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1281 - accuracy: 0.9619 - precision: 0.9628 - recall: 0.9676\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1228 - accuracy: 0.9605 - precision: 0.9604 - recall: 0.9676\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.1203 - accuracy: 0.9564 - precision: 0.9556 - recall: 0.9651\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1158 - accuracy: 0.9578 - precision: 0.9625 - recall: 0.9601\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1128 - accuracy: 0.9646 - precision: 0.9630 - recall: 0.9726\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1089 - accuracy: 0.9714 - precision: 0.9750 - recall: 0.9726\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.1054 - accuracy: 0.9659 - precision: 0.9677 - recall: 0.9701\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.1045 - accuracy: 0.9687 - precision: 0.9701 - recall: 0.9726\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.1112 - accuracy: 0.9632 - precision: 0.9652 - recall: 0.9676\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.0976 - accuracy: 0.9714 - precision: 0.9726 - recall: 0.9751\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0977 - accuracy: 0.9714 - precision: 0.9680 - recall: 0.9800\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0983 - accuracy: 0.9659 - precision: 0.9631 - recall: 0.9751\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0951 - accuracy: 0.9700 - precision: 0.9726 - recall: 0.9726\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0940 - accuracy: 0.9700 - precision: 0.9702 - recall: 0.9751\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0920 - accuracy: 0.9646 - precision: 0.9676 - recall: 0.9676\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0861 - accuracy: 0.9728 - precision: 0.9704 - recall: 0.9800\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0778 - accuracy: 0.9850 - precision: 0.9851 - recall: 0.9875\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0761 - accuracy: 0.9782 - precision: 0.9800 - recall: 0.9800\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0731 - accuracy: 0.9796 - precision: 0.9730 - recall: 0.9900\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0744 - accuracy: 0.9755 - precision: 0.9776 - recall: 0.9776\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0719 - accuracy: 0.9782 - precision: 0.9800 - recall: 0.9800\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0673 - accuracy: 0.9823 - precision: 0.9826 - recall: 0.9850\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.0765 - accuracy: 0.9755 - precision: 0.9776 - recall: 0.9776\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0702 - accuracy: 0.9768 - precision: 0.9800 - recall: 0.9776\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.0674 - accuracy: 0.9809 - precision: 0.9801 - recall: 0.9850\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0611 - accuracy: 0.9823 - precision: 0.9826 - recall: 0.9850\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0611 - accuracy: 0.9864 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.0567 - accuracy: 0.9796 - precision: 0.9777 - recall: 0.9850\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 696us/step - loss: 0.0576 - accuracy: 0.9864 - precision: 0.9827 - recall: 0.9925\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.0537 - accuracy: 0.9877 - precision: 0.9900 - recall: 0.9875\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "#ADDED A THIRD LAYER OF NEURONS\n",
    "\n",
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'), #adds layer of 128 dense neurons\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # adds another layer with 128 neurons\n",
    "    tf.keras.layers.Dense(256, activation='relu'), # add another layer with 256 neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.05), #lr is learning rate,SGD is the optimizer\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history3 = model3.fit(X_train_scaled, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c19bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 1.0931 - accuracy: 0.6798 - precision: 0.6861 - recall: 0.7631\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.3842 - accuracy: 0.8583 - precision: 0.8981 - recall: 0.8354\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3618 - accuracy: 0.8474 - precision: 0.8322 - recall: 0.9027\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.3166 - accuracy: 0.8692 - precision: 0.8861 - recall: 0.8728\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3274 - accuracy: 0.8706 - precision: 0.9048 - recall: 0.8529\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3114 - accuracy: 0.8774 - precision: 0.8821 - recall: 0.8953\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2925 - accuracy: 0.8706 - precision: 0.8883 - recall: 0.8728\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2691 - accuracy: 0.8896 - precision: 0.9000 - recall: 0.8978\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2624 - accuracy: 0.8869 - precision: 0.9036 - recall: 0.8878\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2590 - accuracy: 0.8992 - precision: 0.9225 - recall: 0.8903\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2811 - accuracy: 0.8896 - precision: 0.9145 - recall: 0.8803\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.2602 - accuracy: 0.8951 - precision: 0.9197 - recall: 0.8853\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2503 - accuracy: 0.9005 - precision: 0.9227 - recall: 0.8928\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2409 - accuracy: 0.9019 - precision: 0.9318 - recall: 0.8853\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2224 - accuracy: 0.9087 - precision: 0.9395 - recall: 0.8903\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2220 - accuracy: 0.8965 - precision: 0.9265 - recall: 0.8803\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2647 - accuracy: 0.8692 - precision: 0.8675 - recall: 0.8978\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.2187 - accuracy: 0.8978 - precision: 0.9382 - recall: 0.8703\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2228 - accuracy: 0.8924 - precision: 0.9237 - recall: 0.8753\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2620 - accuracy: 0.8883 - precision: 0.9038 - recall: 0.8903\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2586 - accuracy: 0.8883 - precision: 0.9164 - recall: 0.8753\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2251 - accuracy: 0.8965 - precision: 0.9243 - recall: 0.8828\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2270 - accuracy: 0.8992 - precision: 0.9360 - recall: 0.8753\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2085 - accuracy: 0.9033 - precision: 0.9484 - recall: 0.8703\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2302 - accuracy: 0.9033 - precision: 0.9412 - recall: 0.8778\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2926 - accuracy: 0.8910 - precision: 0.9043 - recall: 0.8953\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2860 - accuracy: 0.8951 - precision: 0.9402 - recall: 0.8628\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2731 - accuracy: 0.8937 - precision: 0.9261 - recall: 0.8753\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2337 - accuracy: 0.8924 - precision: 0.9193 - recall: 0.8803\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2200 - accuracy: 0.8965 - precision: 0.9265 - recall: 0.8803\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2053 - accuracy: 0.8951 - precision: 0.9500 - recall: 0.8529\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1924 - accuracy: 0.9046 - precision: 0.9485 - recall: 0.8728\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2182 - accuracy: 0.8910 - precision: 0.9496 - recall: 0.8454\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2392 - accuracy: 0.8774 - precision: 0.9060 - recall: 0.8653\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2242 - accuracy: 0.8856 - precision: 0.8914 - recall: 0.9002\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1900 - accuracy: 0.9019 - precision: 0.8730 - recall: 0.9601\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1780 - accuracy: 0.9033 - precision: 0.8947 - recall: 0.9327\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1916 - accuracy: 0.9019 - precision: 0.9660 - recall: 0.8504\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2052 - accuracy: 0.8896 - precision: 0.9545 - recall: 0.8379\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2771 - accuracy: 0.8842 - precision: 0.8930 - recall: 0.8953\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2597 - accuracy: 0.8924 - precision: 0.9423 - recall: 0.8554\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2173 - accuracy: 0.8951 - precision: 0.9576 - recall: 0.8454\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3322 - accuracy: 0.8951 - precision: 0.9629 - recall: 0.8404\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2411 - accuracy: 0.8869 - precision: 0.9492 - recall: 0.8379\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2480 - accuracy: 0.9019 - precision: 0.9387 - recall: 0.8778\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2693 - accuracy: 0.9033 - precision: 0.9459 - recall: 0.8728\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2775 - accuracy: 0.8883 - precision: 0.9208 - recall: 0.8703\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3785 - accuracy: 0.8869 - precision: 0.9274 - recall: 0.8603\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4248 - accuracy: 0.8951 - precision: 0.9263 - recall: 0.8778\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.5411 - accuracy: 0.8678 - precision: 0.9021 - recall: 0.8504\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.4361 - accuracy: 0.8243 - precision: 0.8452 - recall: 0.8304\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.5719 - accuracy: 0.8093 - precision: 0.9711 - recall: 0.6708\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3676 - accuracy: 0.8392 - precision: 0.9354 - recall: 0.7581\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4064 - accuracy: 0.8147 - precision: 0.8338 - recall: 0.8254\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.4126 - accuracy: 0.8556 - precision: 0.9429 - recall: 0.7830\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.3512 - accuracy: 0.8474 - precision: 0.9263 - recall: 0.7830\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3668 - accuracy: 0.8706 - precision: 0.9005 - recall: 0.8579\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3850 - accuracy: 0.8638 - precision: 0.9079 - recall: 0.8354\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3367 - accuracy: 0.8828 - precision: 0.8967 - recall: 0.8878\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 870us/step - loss: 0.3227 - accuracy: 0.8787 - precision: 0.8786 - recall: 0.9027\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3396 - accuracy: 0.8610 - precision: 0.8945 - recall: 0.8454\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3810 - accuracy: 0.8488 - precision: 0.8984 - recall: 0.8155\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3925 - accuracy: 0.8447 - precision: 0.8689 - recall: 0.8429\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3842 - accuracy: 0.8501 - precision: 0.8922 - recall: 0.8254\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3506 - accuracy: 0.8433 - precision: 0.8593 - recall: 0.8529\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3620 - accuracy: 0.8134 - precision: 0.8014 - recall: 0.8753\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3740 - accuracy: 0.8447 - precision: 0.8526 - recall: 0.8653\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.5510 - accuracy: 0.7275 - precision: 0.8764 - recall: 0.5835\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.5404 - accuracy: 0.8311 - precision: 0.8098 - recall: 0.9027\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.5252 - accuracy: 0.7793 - precision: 0.7320 - recall: 0.9401\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.6535 - accuracy: 0.7643 - precision: 0.7127 - recall: 0.9526\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.6077 - accuracy: 0.7193 - precision: 0.6720 - recall: 0.9501\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.5601 - accuracy: 0.7766 - precision: 0.7292 - recall: 0.9401\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.5721 - accuracy: 0.8011 - precision: 0.7576 - recall: 0.9352\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.6915 - accuracy: 0.7411 - precision: 0.6994 - recall: 0.9227\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.4916 - accuracy: 0.8256 - precision: 0.7923 - recall: 0.9227\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4569 - accuracy: 0.8283 - precision: 0.7996 - recall: 0.9152\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4345 - accuracy: 0.8433 - precision: 0.8295 - recall: 0.8978\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.4345 - accuracy: 0.8447 - precision: 0.8491 - recall: 0.8703\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4327 - accuracy: 0.8460 - precision: 0.8396 - recall: 0.8878\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4417 - accuracy: 0.8379 - precision: 0.8079 - recall: 0.9227\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4250 - accuracy: 0.8515 - precision: 0.8411 - recall: 0.8978\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3930 - accuracy: 0.8706 - precision: 0.8883 - recall: 0.8728\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3919 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3946 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3873 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.3849 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3849 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3896 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3859 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3845 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3884 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3846 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3862 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3868 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3852 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3892 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3853 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3857 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3841 - accuracy: 0.8706 - precision: 0.8903 - recall: 0.8703\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "#CHANGED THE OPTIMIZER\n",
    "#Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
    "\n",
    "model4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'), #adds layer of 128 dense neurons\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # adds another layer with 128 neurons\n",
    "    tf.keras.layers.Dense(256, activation='relu'), # add another layer with 256 neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model4.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.05), #lr is learning rate,Adam is the optimizer\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history4 = model4.fit(X_train_scaled, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49708cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6403 - precision: 0.6473 - recall: 0.7506\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.8338 - precision: 0.8163 - recall: 0.8978\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8583 - precision: 0.8578 - recall: 0.8878\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8719 - precision: 0.8735 - recall: 0.8953\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8692 - precision: 0.8692 - recall: 0.8953\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8597 - precision: 0.8617 - recall: 0.8853\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3275 - accuracy: 0.8856 - precision: 0.8875 - recall: 0.9052\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3290 - accuracy: 0.8692 - precision: 0.8640 - recall: 0.9027\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.3296 - accuracy: 0.8733 - precision: 0.8720 - recall: 0.9002\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.8828 - precision: 0.8759 - recall: 0.9152\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3127 - accuracy: 0.8869 - precision: 0.8841 - recall: 0.9127\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.3139 - accuracy: 0.8774 - precision: 0.8729 - recall: 0.9077\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.9077\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8869 - precision: 0.8822 - recall: 0.9152\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3014 - accuracy: 0.8883 - precision: 0.8881 - recall: 0.9102\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2906 - accuracy: 0.8801 - precision: 0.8717 - recall: 0.9152\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8842 - precision: 0.8816 - recall: 0.9102\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2835 - accuracy: 0.8896 - precision: 0.8828 - recall: 0.9202\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2870 - accuracy: 0.8910 - precision: 0.8831 - recall: 0.9227\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.8951 - precision: 0.8876 - recall: 0.9252\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.2776 - accuracy: 0.8924 - precision: 0.8889 - recall: 0.9177\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2758 - accuracy: 0.8951 - precision: 0.8857 - recall: 0.9277\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2678 - accuracy: 0.8951 - precision: 0.8857 - recall: 0.9277\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.2667 - accuracy: 0.8965 - precision: 0.8916 - recall: 0.9227\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2688 - accuracy: 0.9019 - precision: 0.9002 - recall: 0.9227\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.8965 - precision: 0.8897 - recall: 0.9252\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2623 - accuracy: 0.9060 - precision: 0.9049 - recall: 0.9252\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2634 - accuracy: 0.8951 - precision: 0.8990 - recall: 0.9102\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9060 - precision: 0.8971 - recall: 0.9352\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.9019 - precision: 0.9002 - recall: 0.9227\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9019 - precision: 0.8926 - recall: 0.9327\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2439 - accuracy: 0.9087 - precision: 0.9113 - recall: 0.9227\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9155 - precision: 0.9065 - recall: 0.9426\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2421 - accuracy: 0.9074 - precision: 0.9071 - recall: 0.9252\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.9019 - precision: 0.8983 - recall: 0.9252\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2271 - accuracy: 0.9114 - precision: 0.9078 - recall: 0.9327\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9142 - precision: 0.9082 - recall: 0.9377\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2228 - accuracy: 0.9155 - precision: 0.9084 - recall: 0.9401\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2224 - accuracy: 0.9169 - precision: 0.9208 - recall: 0.9277\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9169 - precision: 0.9106 - recall: 0.9401\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2225 - accuracy: 0.9183 - precision: 0.9189 - recall: 0.9327\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2177 - accuracy: 0.9142 - precision: 0.9163 - recall: 0.9277\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2136 - accuracy: 0.9223 - precision: 0.9279 - recall: 0.9302\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2097 - accuracy: 0.9183 - precision: 0.9108 - recall: 0.9426\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.9251 - precision: 0.9282 - recall: 0.9352\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9237 - precision: 0.9218 - recall: 0.9401\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2037 - accuracy: 0.9183 - precision: 0.9189 - recall: 0.9327\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.2050 - accuracy: 0.9237 - precision: 0.9218 - recall: 0.9401\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2027 - accuracy: 0.9169 - precision: 0.9187 - recall: 0.9302\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9264 - precision: 0.9242 - recall: 0.9426\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1919 - accuracy: 0.9251 - precision: 0.9240 - recall: 0.9401\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.1980 - accuracy: 0.9251 - precision: 0.9199 - recall: 0.9451\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1850 - accuracy: 0.9183 - precision: 0.9169 - recall: 0.9352\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1940 - accuracy: 0.9305 - precision: 0.9332 - recall: 0.9401\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9319 - precision: 0.9270 - recall: 0.9501\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1862 - accuracy: 0.9237 - precision: 0.9218 - recall: 0.9401\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1836 - accuracy: 0.9264 - precision: 0.9263 - recall: 0.9401\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1754 - accuracy: 0.9292 - precision: 0.9309 - recall: 0.9401\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9292 - precision: 0.9246 - recall: 0.9476\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1752 - accuracy: 0.9360 - precision: 0.9296 - recall: 0.9551\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1703 - accuracy: 0.9278 - precision: 0.9286 - recall: 0.9401\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1776 - accuracy: 0.9237 - precision: 0.9218 - recall: 0.9401\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1720 - accuracy: 0.9360 - precision: 0.9338 - recall: 0.9501\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1642 - accuracy: 0.9387 - precision: 0.9363 - recall: 0.9526\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1582 - accuracy: 0.9469 - precision: 0.9436 - recall: 0.9601\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1685 - accuracy: 0.9332 - precision: 0.9356 - recall: 0.9426\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1587 - accuracy: 0.9360 - precision: 0.9338 - recall: 0.9501\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1516 - accuracy: 0.9469 - precision: 0.9480 - recall: 0.9551\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1488 - accuracy: 0.9469 - precision: 0.9436 - recall: 0.9601\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1510 - accuracy: 0.9346 - precision: 0.9337 - recall: 0.9476\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1512 - accuracy: 0.9414 - precision: 0.9387 - recall: 0.9551\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1497 - accuracy: 0.9401 - precision: 0.9407 - recall: 0.9501\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1436 - accuracy: 0.9523 - precision: 0.9485 - recall: 0.9651\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1406 - accuracy: 0.9414 - precision: 0.9409 - recall: 0.9526\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1366 - accuracy: 0.9523 - precision: 0.9507 - recall: 0.9626\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1276 - accuracy: 0.9632 - precision: 0.9652 - recall: 0.9676\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1386 - accuracy: 0.9469 - precision: 0.9480 - recall: 0.9551\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1264 - accuracy: 0.9537 - precision: 0.9531 - recall: 0.9626\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1337 - accuracy: 0.9455 - precision: 0.9524 - recall: 0.9476\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1317 - accuracy: 0.9537 - precision: 0.9553 - recall: 0.9601\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.1180 - accuracy: 0.9591 - precision: 0.9649 - recall: 0.9601\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1257 - accuracy: 0.9523 - precision: 0.9507 - recall: 0.9626\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1219 - accuracy: 0.9482 - precision: 0.9526 - recall: 0.9526\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1230 - accuracy: 0.9550 - precision: 0.9577 - recall: 0.9601\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.1289 - accuracy: 0.9510 - precision: 0.9574 - recall: 0.9526\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1178 - accuracy: 0.9564 - precision: 0.9533 - recall: 0.9676\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1146 - accuracy: 0.9619 - precision: 0.9560 - recall: 0.9751\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1088 - accuracy: 0.9605 - precision: 0.9627 - recall: 0.9651\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1025 - accuracy: 0.9700 - precision: 0.9656 - recall: 0.9800\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1050 - accuracy: 0.9673 - precision: 0.9677 - recall: 0.9726\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1006 - accuracy: 0.9659 - precision: 0.9631 - recall: 0.9751\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0990 - accuracy: 0.9632 - precision: 0.9629 - recall: 0.9701\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.1138 - accuracy: 0.9523 - precision: 0.9507 - recall: 0.9626\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1017 - accuracy: 0.9646 - precision: 0.9607 - recall: 0.9751\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1022 - accuracy: 0.9632 - precision: 0.9606 - recall: 0.9726\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0929 - accuracy: 0.9755 - precision: 0.9776 - recall: 0.9776\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.0914 - accuracy: 0.9714 - precision: 0.9726 - recall: 0.9751\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0841 - accuracy: 0.9755 - precision: 0.9728 - recall: 0.9825\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0742 - accuracy: 0.9768 - precision: 0.9752 - recall: 0.9825\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0878 - accuracy: 0.9659 - precision: 0.9724 - recall: 0.9651\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "#ADDED A DROPOUT LAYER AND CHANGED OPTIMIZER BACK TO SGD\n",
    "#The dropout hyperparameter is the probability of training a given node in a layer, where 1.0 means no dropout, and 0.0 means no outputs from the layer.\n",
    "\n",
    "model5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'), #adds layer of 128 dense neurons\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # adds another layer with 128 neurons\n",
    "    tf.keras.layers.Dense(256, activation='relu'), # add another layer with 256 neurons\n",
    "    tf.keras.layers.Dropout(.5, input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.05), #lr is learning rate,SGD is the optimizer\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history5 = model5.fit(X_train_scaled, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b67855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6088 - accuracy: 0.6798 - precision: 0.6687 - recall: 0.8204\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8501 - precision: 0.8506 - recall: 0.8803\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8719 - precision: 0.8699 - recall: 0.9002\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8760 - precision: 0.8726 - recall: 0.9052\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8801 - precision: 0.8826 - recall: 0.9002\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3173 - accuracy: 0.8787 - precision: 0.8732 - recall: 0.9102\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8896 - precision: 0.8883 - recall: 0.9127\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3057 - accuracy: 0.8787 - precision: 0.8714 - recall: 0.9127\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.8774 - precision: 0.8802 - recall: 0.8978\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2913 - accuracy: 0.8856 - precision: 0.8747 - recall: 0.9227\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2838 - accuracy: 0.9019 - precision: 0.9022 - recall: 0.9202\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2824 - accuracy: 0.8869 - precision: 0.8786 - recall: 0.9202\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2690 - accuracy: 0.9019 - precision: 0.8945 - recall: 0.9302\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.9019 - precision: 0.8983 - recall: 0.9252\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.9033 - precision: 0.9044 - recall: 0.9202\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2514 - accuracy: 0.8992 - precision: 0.8902 - recall: 0.9302\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2532 - accuracy: 0.9142 - precision: 0.9082 - recall: 0.9377\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2465 - accuracy: 0.8978 - precision: 0.8900 - recall: 0.9277\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.9087 - precision: 0.9034 - recall: 0.9327\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2357 - accuracy: 0.9033 - precision: 0.9024 - recall: 0.9227\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2335 - accuracy: 0.9114 - precision: 0.9138 - recall: 0.9252\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9114 - precision: 0.9118 - recall: 0.9277\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2231 - accuracy: 0.9074 - precision: 0.9031 - recall: 0.9302\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9169 - precision: 0.9167 - recall: 0.9327\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2218 - accuracy: 0.9074 - precision: 0.9132 - recall: 0.9177\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9183 - precision: 0.9089 - recall: 0.9451\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2085 - accuracy: 0.9183 - precision: 0.9148 - recall: 0.9377\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2162 - accuracy: 0.9101 - precision: 0.9198 - recall: 0.9152\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1996 - accuracy: 0.9264 - precision: 0.9305 - recall: 0.9352\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9210 - precision: 0.9214 - recall: 0.9352\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1864 - accuracy: 0.9223 - precision: 0.9216 - recall: 0.9377\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1905 - accuracy: 0.9278 - precision: 0.9307 - recall: 0.9377\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1831 - accuracy: 0.9237 - precision: 0.9238 - recall: 0.9377\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1826 - accuracy: 0.9251 - precision: 0.9282 - recall: 0.9352\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1801 - accuracy: 0.9264 - precision: 0.9221 - recall: 0.9451\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9414 - precision: 0.9409 - recall: 0.9526\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1635 - accuracy: 0.9332 - precision: 0.9272 - recall: 0.9526\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1537 - accuracy: 0.9455 - precision: 0.9392 - recall: 0.9626\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1662 - accuracy: 0.9332 - precision: 0.9335 - recall: 0.9451\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1746 - accuracy: 0.9292 - precision: 0.9225 - recall: 0.9501\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1594 - accuracy: 0.9428 - precision: 0.9454 - recall: 0.9501\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1577 - accuracy: 0.9251 - precision: 0.9240 - recall: 0.9401\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1443 - accuracy: 0.9401 - precision: 0.9407 - recall: 0.9501\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1427 - accuracy: 0.9482 - precision: 0.9481 - recall: 0.9576\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1350 - accuracy: 0.9428 - precision: 0.9521 - recall: 0.9426\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1424 - accuracy: 0.9346 - precision: 0.9337 - recall: 0.9476\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1294 - accuracy: 0.9482 - precision: 0.9549 - recall: 0.9501\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1343 - accuracy: 0.9496 - precision: 0.9505 - recall: 0.9576\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9414 - precision: 0.9431 - recall: 0.9501\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1135 - accuracy: 0.9605 - precision: 0.9604 - recall: 0.9676\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1197 - accuracy: 0.9537 - precision: 0.9553 - recall: 0.9601\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1162 - accuracy: 0.9469 - precision: 0.9436 - recall: 0.9601\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1032 - accuracy: 0.9646 - precision: 0.9699 - recall: 0.9651\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1053 - accuracy: 0.9564 - precision: 0.9601 - recall: 0.9601\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1103 - accuracy: 0.9591 - precision: 0.9580 - recall: 0.9676\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1021 - accuracy: 0.9605 - precision: 0.9559 - recall: 0.9726\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1047 - accuracy: 0.9605 - precision: 0.9604 - recall: 0.9676\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9659 - precision: 0.9608 - recall: 0.9776\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0825 - accuracy: 0.9646 - precision: 0.9630 - recall: 0.9726\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9714 - precision: 0.9703 - recall: 0.9776\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0798 - accuracy: 0.9741 - precision: 0.9751 - recall: 0.9776\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0834 - accuracy: 0.9700 - precision: 0.9702 - recall: 0.9751\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0722 - accuracy: 0.9837 - precision: 0.9826 - recall: 0.9875\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0680 - accuracy: 0.9755 - precision: 0.9752 - recall: 0.9800\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9700 - precision: 0.9633 - recall: 0.9825\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0916 - accuracy: 0.9646 - precision: 0.9699 - recall: 0.9651\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0697 - accuracy: 0.9714 - precision: 0.9750 - recall: 0.9726\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0605 - accuracy: 0.9850 - precision: 0.9899 - recall: 0.9825\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9837 - precision: 0.9875 - recall: 0.9825\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0594 - accuracy: 0.9823 - precision: 0.9778 - recall: 0.9900\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0716 - accuracy: 0.9741 - precision: 0.9775 - recall: 0.9751\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0619 - accuracy: 0.9809 - precision: 0.9825 - recall: 0.9825\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0827 - accuracy: 0.9673 - precision: 0.9631 - recall: 0.9776\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0553 - accuracy: 0.9782 - precision: 0.9753 - recall: 0.9850\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0447 - accuracy: 0.9877 - precision: 0.9900 - recall: 0.9875\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0333 - accuracy: 0.9932 - precision: 0.9877 - recall: 1.0000\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0355 - accuracy: 0.9918 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0393 - accuracy: 0.9864 - precision: 0.9900 - recall: 0.9850\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0588 - accuracy: 0.9755 - precision: 0.9752 - recall: 0.9800\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0715 - accuracy: 0.9687 - precision: 0.9701 - recall: 0.9726\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0463 - accuracy: 0.9823 - precision: 0.9826 - recall: 0.9850\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0491 - accuracy: 0.9864 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0324 - accuracy: 0.9946 - precision: 0.9926 - recall: 0.9975\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0345 - accuracy: 0.9891 - precision: 0.9925 - recall: 0.9875\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9905 - precision: 0.9876 - recall: 0.9950\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9891 - precision: 0.9876 - recall: 0.9925\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9946 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9891 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9905 - precision: 0.9900 - recall: 0.9925\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0205 - accuracy: 0.9973 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0173 - accuracy: 0.9973 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9986 - precision: 0.9975 - recall: 1.0000\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0290 - accuracy: 0.9905 - precision: 0.9900 - recall: 0.9925\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0294 - accuracy: 0.9864 - precision: 0.9851 - recall: 0.9900\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9605 - precision: 0.9604 - recall: 0.9676\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0768 - accuracy: 0.9837 - precision: 0.9826 - recall: 0.9875\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0396 - accuracy: 0.9877 - precision: 0.9876 - recall: 0.9900\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0286 - accuracy: 0.9891 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0202 - accuracy: 0.9932 - precision: 0.9950 - recall: 0.9925\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0219 - accuracy: 0.9959 - precision: 0.9950 - recall: 0.9975\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "#CHANGED THE MOMENTUM OF THE SGD \n",
    "\n",
    "model6 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'), #adds layer of 128 dense neurons\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # adds another layer with 128 neurons\n",
    "    tf.keras.layers.Dense(256, activation='relu'), # add another layer with 256 neurons\n",
    "    tf.keras.layers.Dropout(.5, input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model6.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.05, momentum=0.5), #lr is learning rate, momentum is the speed of gradient descent,SGD is the optimizer\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history6 = model6.fit(X_train_scaled, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8524a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model6.predict(X_test_scaled)\n",
    "prediction_classes = [\n",
    "    1 if prob > 0.75 else 0 for prob in np.ravel(predictions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f50f0f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67 10]\n",
      " [20 87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(Y_test, prediction_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7344b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Precision: 0.90\n",
      "Recall: 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(Y_test, prediction_classes):.2f}')\n",
    "print(f'Precision: {precision_score(Y_test, prediction_classes):.2f}')\n",
    "print(f'Recall: {recall_score(Y_test, prediction_classes):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (18, 8)\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "\n",
    "plt.plot(\n",
    "    np.arange(1, 101), \n",
    "    history1.history['loss'], label='Loss'\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(1, 101), \n",
    "    history1.history['accuracy'], label='Accuracy'\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(1, 101), \n",
    "    history1.history['precision'], label='Precision'\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(1, 101), \n",
    "    history1.history['recall'], label='Recall'\n",
    ")\n",
    "plt.title('Evaluation metrics', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
